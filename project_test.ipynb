{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "median-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://cnwoman-bot.github.io/evil-man/\")\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "soup.prettify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-scout",
   "metadata": {},
   "source": [
    "## getting crimes list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sitting-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_within(div):\n",
    "    p = div.next_sibling.next_sibling\n",
    "    lst_text = [a.text for a in p.find_all('a')]\n",
    "    return lst_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exotic-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i.parent.text.split('\\n') for i in soup.find_all('a') if i.text.startswith('判决日期')]\n",
    "o = []\n",
    "for t in text:\n",
    "    if len(t) <= 3:\n",
    "        o.append(t[0])\n",
    "    else:\n",
    "        for s in t:\n",
    "            if '判决日期' not in s:\n",
    "                o.append(s)\n",
    "o = list(set(o))\n",
    "other1 = o\n",
    "\n",
    "other2 = ['新疆喀什大学文学院援疆博士王明科','云南云南大学文学院副教授蔡英杰性骚扰留学生被公开处分，现任福建师范大学教授','甘肃兰州大学大气科学学院副院长张文煜被曝性侵',\n",
    "         '上海戏剧学院教务处处长厉震林性骚扰，已无链接','央美设计学院院长宋协伟被指控性骚扰、猥亵女学生', '原北京中央民族大学文学院与新闻传播学院刘立刚性骚扰',\n",
    "         '湖北美院偷拍女生裙底把视频发到了p站，无语，链接不放了','北京电影学院阿廖莎性侵案','北京电影学院侯亮平事件']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "operating-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = [d for d in soup.find_all('div',class_=\"language-plaintext highlighter-rouge\") if '本小节合计' in d.text]\n",
    "crime = []\n",
    "for d in div:\n",
    "    crime += get_news_within(d)\n",
    "crime += other1\n",
    "crime += other2\n",
    "l = ['亳州6·15杀人案,邻居眼中的老实人,为何连杀4人','四川一名大学本科男子刘某在成都开往深圳的火车上猥亵9岁女童','浙大学生努某某强奸被判一年半，学校不与开除，留校察看','猥亵女童的网红“豆浆王子”蒙顺宁，出狱后获得公益组织爱心帮扶',\n",
    " '西南某大学法学院22岁男生偷拍女生裙底',\n",
    " '陕西安康石泉30岁的男子索爱一女子不成跳江自杀，女子被判决赔偿各项损失七万元']\n",
    "crime += l\n",
    "out1 = [i for i in crime if \"洋媳妇\" in i][0]\n",
    "out2 = [i for i in crime if \"所有的功劳就还是男性的\" in i][0]\n",
    "out2\n",
    "crime.remove(out1)\n",
    "crime.remove(out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some crimes are nested under h3 tags not div - but really messy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-neighbor",
   "metadata": {},
   "source": [
    "## getting cities dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still need another scraping to get a list of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "presidential-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the city list\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "r_city = requests.get(\"https://en.wikipedia.org/wiki/List_of_cities_in_China\")\n",
    "s_city = BeautifulSoup(r_city.text,'html.parser')\n",
    "s_city.prettify()\n",
    "\n",
    "import chinese_converter\n",
    "\n",
    "def divide(string):\n",
    "    string = chinese_converter.to_simplified(string)\n",
    "    if '特别行政区' in string: \n",
    "        return string[0:2]\n",
    "    else:\n",
    "        return string[:-1]\n",
    "\n",
    "dct_city = {}\n",
    "normal_cities = s_city.find_all('tr',bgcolor=\"Lavender\")\n",
    "for c in normal_cities:\n",
    "    lst = c.text.split()\n",
    "    cn_name = lst[1]\n",
    "    cn_name = divide(cn_name)\n",
    "    dct_city[cn_name] = lst[0]\n",
    "    \n",
    "special_cities = s_city.find_all('tr',bgcolor=\"Thistle\")+ s_city.find_all('tr',bgcolor=\"Moccasin\")\n",
    "for c in special_cities:\n",
    "    txt = re.sub(' ','',c.text) #this is for the special case of HK\n",
    "    lst = txt.split()\n",
    "    cn_name = lst[1]\n",
    "    cn_name = divide(cn_name)\n",
    "    dct_city[cn_name] = lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from china_cities import *\n",
    "#this package returns all cities on different levels (e.g. municipal vs counties), \n",
    "#hence we don't use cities from this package;we only use the province part\n",
    "province = [re.findall(r'\\w+',re.sub(' ','',p).lower())[0] for p in cities.get_provinces()]\n",
    "province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = {i[:-1] for i in cities.get_cities_cn()} - set(dct_city.keys())\n",
    "counties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-links",
   "metadata": {},
   "source": [
    "## matching crimes to cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "italic-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_news = {}\n",
    "lst_matched = []\n",
    "for c in dct_city.keys():\n",
    "    c_lst = [n for n in crime if c in n]\n",
    "    dct_news[c] = len(c_lst)\n",
    "    lst_matched += c_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bearing-mason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-harvey",
   "metadata": {},
   "source": [
    "## dealing with left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_left = [n for n in crime if n not in lst_matched]\n",
    "lst_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "embedded-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "thousand-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is still flawed\n",
    "#requesting the link of the news to get city info\n",
    "def into_link(string):\n",
    "    url = [a for a in soup.find_all('a') if string in a.text][0]['href']\n",
    "    if 'http' not in url:\n",
    "        url = 'http://' + url\n",
    "    rr = requests.get(url)\n",
    "    ss = BeautifulSoup(rr.text,'html.parser')\n",
    "    ss.text.split()\n",
    "    if 'forbidden' in ss.text.lower() or 'error' in ss.text.lower() or '删除' in ss.text.lower() or '找不到' in ss.text.lower():\n",
    "        lst_no_loc.remove(string)\n",
    "    else:\n",
    "        loc_info = [t for t in set(jieba.cut(s4.text)) if '市' in t]\n",
    "        if len(loc_info) == 1:\n",
    "            city = loc_info[0]\n",
    "            if city in dct_city.keys():\n",
    "                dct_news[city] += 1\n",
    "                lst_matched.append(string)\n",
    "                lst_no_loc.remove(string)\n",
    "            else:\n",
    "                prov = [c.province for c in cities.get_cities() if c.name_cn == city]\n",
    "                if len(prov) == 1:\n",
    "                    p = prov[0]\n",
    "                    county_owner(p, city)\n",
    "                    lst_no_loc.remove(string)\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "baking-cardiff",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidURL",
     "evalue": "Invalid URL 'http://': No host supplied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-40d513d79cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst_no_loc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minto_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-250-b63938f0a44f>\u001b[0m in \u001b[0;36minto_link\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'http'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         p.prepare(\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid URL %r: No host supplied\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# In general, we want to try IDNA encoding the hostname if the string contains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidURL\u001b[0m: Invalid URL 'http://': No host supplied"
     ]
    }
   ],
   "source": [
    "for l in lst_no_loc:\n",
    "    into_link(l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-graph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "impossible-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_location(string):\n",
    "    seg_list = jieba.cut(string)\n",
    "    words = list(seg_list)\n",
    "    fw = pinyin.get(words[0], format=\"strip\", delimiter=\"\")\n",
    "    if fw in province and words[1] in counties:\n",
    "        return fw, words[1]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "short-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_owner(fw, county_name):\n",
    "    county_tag = [tag for tag in s_city.find_all('span',title=\"Chinese-language text\") if county_name in tag.text][0]\n",
    "    owner_pinyin = [t for t in county_tag.parent.parent.next_siblings][3].text  \n",
    "    owner_city_lst = [c.name_cn for c in cities.get_cities() if fw in c.province.lower() and c.name_en == owner_pinyin]\n",
    "    if len(owner_city_lst) != 1:\n",
    "        if 'none' not in owner_pinyin:\n",
    "            return False\n",
    "        else:\n",
    "            owner_city = county_name\n",
    "    else:\n",
    "        owner_city = owner_city_lst[0][:-1]\n",
    "        \n",
    "    if owner_city in dct_news.keys(): #because of the special case of enshi, which is not a municipal city but has no governing city\n",
    "        dct_news[owner_city] += 1\n",
    "    else:\n",
    "        dct_news[owner_city] = 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_no_loc = []\n",
    "for l in lst_left:\n",
    "    if has_location(l) != None:\n",
    "        prov = has_location(l)[0]\n",
    "        county = has_location(l)[1]\n",
    "        if county_owner(prov, county) != False:\n",
    "            lst_matched.append(l)\n",
    "        else:\n",
    "            lst_no_loc.append(l)\n",
    "    else:\n",
    "        lst_no_loc.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bacterial-petersburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_news.keys()\n",
    "len(lst_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-agency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-houston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-beads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-tumor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-reading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-sound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-nirvana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-armstrong",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-ideal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-residence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-divide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-child",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-supplier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#earlier codes for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "internal-blair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'墨': 2, '榔头': 0, '斧头': 3, '刀': 163, '硫酸': 2, '锄头': 1, '棍': 7}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_weap = {'刀','棍','硫酸','斧头','锄头','榔头','墨'}\n",
    "dct_w = {}\n",
    "for w in set_weap:\n",
    "    lst_crime = [n for n in crime if w in n]\n",
    "    dct_w[w] = len(lst_crime)\n",
    "dct_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "inappropriate-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'强暴': 10,\n",
       " '杀害': 183,\n",
       " '猥亵': 281,\n",
       " '性侵': 152,\n",
       " '强奸': 179,\n",
       " '家暴': 30,\n",
       " '溺': 2,\n",
       " '毒': 18,\n",
       " '偷拍': 70,\n",
       " '烧': 21,\n",
       " '殴打': 50,\n",
       " '勒': 20,\n",
       " '推': 9,\n",
       " '碎尸': 10,\n",
       " '埋': 14,\n",
       " '药': 23,\n",
       " '偷窥': 12}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_crime = {'杀害','猥亵','强奸','强暴','家暴','殴打','偷拍','偷窥','性侵','毒','药','埋','溺','推','勒','碎尸','毒','药','烧'}\n",
    "dct_c = {}\n",
    "for c in set_crime:\n",
    "    lst_crime = [n for n in crime if c in n]\n",
    "    dct_c[c] = len(lst_crime)\n",
    "dct_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "arranged-vintage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['女德班成果：“中国女孩只属于中国男孩”', '广东东莞蒙正国学馆“女德班” 无证办学被责令停办，曾称要做女强人就得切除子宫乳房']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n in news if '女德' in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-wrapping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-moment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-michael",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "saving-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = requests.get('https://baijiahao.baidu.com/s?id=1622347467847141868&wfr=spider&for=pc')\n",
    "s4 = BeautifulSoup(rr.text,'html.parser')\n",
    "s4.prettify()\n",
    "[t for t in set(jieba.cut(s4.text)) if '省' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-insulin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-entertainment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-camping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-territory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
