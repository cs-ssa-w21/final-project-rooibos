{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rural-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://cnwoman-bot.github.io/evil-man/\")\n",
    "soup = BeautifulSoup(r.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.prettify()\n",
    "news = [i.text for i in soup.find_all(\"a\")[24:]]\n",
    "len(news)\n",
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "forward-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_within(div):\n",
    "    p = div.next_sibling.next_sibling\n",
    "    lst_text = [a.text for a in p.find_all('a')]\n",
    "    return lst_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i.parent.text.split('\\n') for i in soup.find_all('a') if i.text.startswith('判决日期')]\n",
    "o = []\n",
    "for t in text:\n",
    "    if len(t) <= 3:\n",
    "        o.append(t[0])\n",
    "    else:\n",
    "        for s in t:\n",
    "            if '判决日期' not in s:\n",
    "                o.append(s)\n",
    "o = list(set(o))\n",
    "other1 = o\n",
    "\n",
    "other2 = ['新疆喀什大学文学院援疆博士王明科','云南云南大学文学院副教授蔡英杰性骚扰留学生被公开处分，现任福建师范大学教授','甘肃兰州大学大气科学学院副院长张文煜被曝性侵',\n",
    "         '上海戏剧学院教务处处长厉震林性骚扰，已无链接','央美设计学院院长宋协伟被指控性骚扰、猥亵女学生', '原北京中央民族大学文学院与新闻传播学院刘立刚性骚扰',\n",
    "         '湖北美院偷拍女生裙底把视频发到了p站，无语，链接不放了','北京电影学院阿廖莎性侵案','北京电影学院侯亮平事件']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = [d for d in soup.find_all('div',class_=\"language-plaintext highlighter-rouge\") if '本小节合计' in d.text]\n",
    "crime = []\n",
    "for d in div:\n",
    "    crime += get_news_within(d)\n",
    "crime += other1\n",
    "crime += other2\n",
    "l = ['亳州6·15杀人案,邻居眼中的老实人,为何连杀4人','四川一名大学本科男子刘某在成都开往深圳的火车上猥亵9岁女童','浙大学生努某某强奸被判一年半，学校不与开除，留校察看','猥亵女童的网红“豆浆王子”蒙顺宁，出狱后获得公益组织爱心帮扶',\n",
    " '西南某大学法学院22岁男生偷拍女生裙底',\n",
    " '陕西安康石泉30岁的男子索爱一女子不成跳江自杀，女子被判决赔偿各项损失七万元']\n",
    "crime += l\n",
    "out1 = [i for i in crime if \"洋媳妇\" in i][0]\n",
    "out2 = [i for i in crime if \"所有的功劳就还是男性的\" in i][0]\n",
    "out2\n",
    "crime.remove(out1)\n",
    "crime.remove(out2)\n",
    "crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "surprised-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 id=\"v1218-20210208-2100\">v1.2.18 (2021/02/08 21:00)</h3>,\n",
       " <h3 id=\"v1217-20210105-1400\">v1.2.17 (2021/01/05 14:00)</h3>,\n",
       " <h3 id=\"男权心里话\">男权心里话</h3>,\n",
       " <h3 id=\"将妻全家灭门案\">将妻全家灭门案</h3>,\n",
       " <h3 id=\"关键词-死亡-婚姻\">关键词 <code class=\"language-plaintext highlighter-rouge\">死亡</code> <code class=\"language-plaintext highlighter-rouge\">婚姻</code></h3>,\n",
       " <h3 id=\"关键词-重伤一级-婚恋\">关键词 <code class=\"language-plaintext highlighter-rouge\">重伤一级</code> <code class=\"language-plaintext highlighter-rouge\">婚恋</code></h3>,\n",
       " <h3 id=\"关键词-违背妇女意志\">关键词 <code class=\"language-plaintext highlighter-rouge\">违背妇女意志</code></h3>,\n",
       " <h3 id=\"关键词-主观故意-女童保护\">关键词 <code class=\"language-plaintext highlighter-rouge\">主观故意</code> <code class=\"language-plaintext highlighter-rouge\">女童保护</code></h3>,\n",
       " <h3 id=\"离婚难\">离婚难</h3>,\n",
       " <h3 id=\"甜甜的恋爱轮到你了\">甜甜的恋爱轮到你了</h3>,\n",
       " <h3 id=\"被结婚\">被结婚</h3>,\n",
       " <h3 id=\"无辜路人\">无辜路人</h3>,\n",
       " <h3 id=\"你敢当我的同事吗\">你敢当我的同事吗</h3>,\n",
       " <h3 id=\"0-3岁\">0-3岁</h3>,\n",
       " <h3 id=\"4-6岁\">4-6岁</h3>,\n",
       " <h3 id=\"7-17岁\">7-17岁</h3>,\n",
       " <h3 id=\"女尸也不放过\">女尸也不放过</h3>,\n",
       " <h3 id=\"反正都是女人的错\">反正都是女人的错</h3>,\n",
       " <h3 id=\"网约车安全专题\">网约车安全专题</h3>,\n",
       " <h3 id=\"与职业头衔无关-高校教授\">与职业头衔无关-高校教授</h3>,\n",
       " <h3 id=\"与学历无关\">与学历无关</h3>,\n",
       " <h3 id=\"性骚扰\">性骚扰</h3>,\n",
       " <h3 id=\"与金钱地位无关\">与金钱地位无关</h3>,\n",
       " <h3 id=\"疫情专题\">疫情专题</h3>,\n",
       " <h3 id=\"护屌新闻大赏\">护屌新闻大赏</h3>,\n",
       " <h3 id=\"男性真心话合集\">男性真心话合集</h3>,\n",
       " <h3 id=\"女德班死灰复燃\">女德班死灰复燃</h3>,\n",
       " <h3 id=\"女性有平等继承权吗\">女性有平等继承权吗</h3>,\n",
       " <h3 id=\"微博厌女话题一览\">微博厌女话题一览</h3>,\n",
       " <h3 id=\"厌女恶臭言论\">厌女恶臭言论</h3>,\n",
       " <h3 id=\"它们可以做-她们不能说\">它们可以做-她们不能说</h3>,\n",
       " <h3 id=\"404是男权的法宝\">404是男权的法宝</h3>]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some crimes are nested under h3 tags not div - but really messy\n",
    "soup.find_all('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still need another scraping to get a list of cities - does wiki has a chinese version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "#earlier codes for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "hazardous-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'墨': 2, '榔头': 0, '斧头': 3, '刀': 163, '硫酸': 2, '锄头': 1, '棍': 7}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_weap = {'刀','棍','硫酸','斧头','锄头','榔头','墨'}\n",
    "dct_w = {}\n",
    "for w in set_weap:\n",
    "    lst_crime = [n for n in crime if w in n]\n",
    "    dct_w[w] = len(lst_crime)\n",
    "dct_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "analyzed-picking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'强暴': 10,\n",
       " '杀害': 183,\n",
       " '猥亵': 281,\n",
       " '性侵': 152,\n",
       " '强奸': 179,\n",
       " '家暴': 30,\n",
       " '溺': 2,\n",
       " '毒': 18,\n",
       " '偷拍': 70,\n",
       " '烧': 21,\n",
       " '殴打': 50,\n",
       " '勒': 20,\n",
       " '推': 9,\n",
       " '碎尸': 10,\n",
       " '埋': 14,\n",
       " '药': 23,\n",
       " '偷窥': 12}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_crime = {'杀害','猥亵','强奸','强暴','家暴','殴打','偷拍','偷窥','性侵','毒','药','埋','溺','推','勒','碎尸','毒','药','烧'}\n",
    "dct_c = {}\n",
    "for c in set_crime:\n",
    "    lst_crime = [n for n in crime if c in n]\n",
    "    dct_c[c] = len(lst_crime)\n",
    "dct_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "alive-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['女德班成果：“中国女孩只属于中国男孩”', '广东东莞蒙正国学馆“女德班” 无证办学被责令停办，曾称要做女强人就得切除子宫乳房']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n in news if '女德' in n]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
